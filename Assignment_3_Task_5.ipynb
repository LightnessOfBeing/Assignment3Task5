{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gIHYBCMYh-m"
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YCagcHNtfysV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import torch.utils.data\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HyX-qabVYlWw"
   },
   "source": [
    "# Importing Dataset and Training settings\n",
    "## Please DO NOT change this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uJ0twcz4f7B-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch version: 1.8.2\n",
      "cuda version: 10.2\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(f'Pytorch version: {torch.__version__}')\n",
    "print(f'cuda version: {torch.version.cuda}')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ouput should be:\n",
    "Pytorch version: 1.8.2\n",
    "cuda version: 10.2\n",
    "cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "J4NSJID_f6-V"
   },
   "outputs": [],
   "source": [
    "def START_seed():\n",
    "    seed = 42\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3CNiQdv2sSCB"
   },
   "outputs": [],
   "source": [
    "CLASSES = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "127j8F6daEoP"
   },
   "source": [
    "# Task5:One Network to Best Them All\n",
    "### Using the previous observations and what you learned in the lecture please modify the following architecture to achieve best possible accuracy.\n",
    "Examples of architectural changes to the baseline: adding more convolutional layers, more channels perconvolution layer, more fully connected layers, dropout, BN, data-augmentations, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSES = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "# Creating labels for dogcat output. Cat 3 -> 1, Dog: 5 -> 2, Everything else -> 0.\n",
    "\n",
    "def convert_normal_to_dogcat(x: int):\n",
    "    if x == 3:\n",
    "        return 1\n",
    "    elif x == 5:\n",
    "        return 2\n",
    "    return 0\n",
    "\n",
    "def convert_dogcat_to_normal(x: int):\n",
    "    if x == 1:\n",
    "        return 3\n",
    "    return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# We need to extend default dataset, because we have additional target for dogcat output.\n",
    "\n",
    "class CIFAR10Extended(torchvision.datasets.CIFAR10):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.targets_dogcat = [convert_normal_to_dogcat(x) for x in self.targets]\n",
    "    \n",
    "    def __getitem__(self, index: int) -> List[torch.Tensor]:\n",
    "        img = self.data[index]\n",
    "        img = Image.fromarray(img)\n",
    "        img = self.transform(img)\n",
    "        return img, self.targets[index], self.targets_dogcat[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 256\n",
    "test_batch_size = 256\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "   transforms.RandomHorizontalFlip(),\n",
    "   transforms.ToTensor(),\n",
    "   transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "   transforms.ToTensor(),\n",
    "   transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_set = CIFAR10Extended(root='./data', train=True, download=True, transform=train_transform)\n",
    "test_set = CIFAR10Extended(root='./data', train=False, download=True, transform=test_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=train_batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=test_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, in_planes: int, growth_rate: int) -> None:\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv1 = nn.Conv2d(in_planes, 4*growth_rate, kernel_size=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(4*growth_rate)\n",
    "        self.conv2 = nn.Conv2d(4*growth_rate, growth_rate, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        out = self.conv1(F.relu(self.bn1(x)))\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        out = torch.cat([out,x], 1)\n",
    "        return out\n",
    "\n",
    "class Transition(nn.Module):\n",
    "    def __init__(self, in_planes: int, out_planes: int):\n",
    "        super(Transition, self).__init__()\n",
    "        self.bn = nn.BatchNorm2d(in_planes)\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=1, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        out = self.conv(F.relu(self.bn(x)))\n",
    "        out = F.avg_pool2d(out, 2)\n",
    "        return out\n",
    "\n",
    "class DogCatHead(nn.Module):\n",
    "    def __init__(self, num_features: int, num_classes: int) -> None:\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(num_features, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear(x)\n",
    "\n",
    "class DenseNetDogCat(nn.Module):\n",
    "    def __init__(self, block: nn.Module, nblocks: int, growth_rate: int=12, reduction: float=0.5, num_classes: int=10):\n",
    "        START_seed()\n",
    "        super(DenseNetDogCat, self).__init__()\n",
    "        self.growth_rate = growth_rate\n",
    "\n",
    "        num_planes = 2*growth_rate\n",
    "        self.conv1 = nn.Conv2d(3, num_planes, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "        self.dense1 = self._make_dense_layers(block, num_planes, nblocks[0])\n",
    "        num_planes += nblocks[0]*growth_rate\n",
    "        out_planes = int(np.floor(num_planes*reduction))\n",
    "        self.trans1 = Transition(num_planes, out_planes)\n",
    "        num_planes = out_planes\n",
    "\n",
    "        self.dense2 = self._make_dense_layers(block, num_planes, nblocks[1])\n",
    "        num_planes += nblocks[1] * growth_rate\n",
    "        self.bn = nn.BatchNorm2d(num_planes)\n",
    "        self.linear = nn.Linear(num_planes * 16, num_classes)\n",
    "        self.dogcathead = DogCatHead(num_planes * 16, 3)\n",
    "\n",
    "    def _make_dense_layers(self, block: nn.Module, in_planes: int, nblock: int):\n",
    "        layers = []\n",
    "        for i in range(nblock):\n",
    "            layers.append(block(in_planes, self.growth_rate))\n",
    "            in_planes += self.growth_rate\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        out = self.conv1(x)\n",
    "        out = self.trans1(self.dense1(out))\n",
    "        out = self.dense2(out)\n",
    "        out = F.avg_pool2d(out, kernel_size=4)\n",
    "        out = out.view(out.size(0), -1)                \n",
    "        dogcat_out = self.dogcathead(out) \n",
    "        out = self.linear(out)\n",
    "        return out, dogcat_out\n",
    "\n",
    "def densenetdogcat_cifar():\n",
    "    return DenseNetDogCat(Bottleneck, [4, 7], growth_rate=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def train_dogcat(epoch: int, model: nn.Module, optimizer, lambda_: float) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    model.train()\n",
    "\n",
    "    total_loss_per_epoch = 0\n",
    "    correct = 0\n",
    "    correct_dogcat = 0\n",
    "    \n",
    "    for batch_idx, (data, target, target_dogcat) in enumerate(train_loader):\n",
    "        data, target, target_dogcat = data.to(device), target.to(device), target_dogcat.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output, output_dogcat = model(data)\n",
    "        index_pred = torch.argmax(F.softmax(output, dim=1), dim=1)        \n",
    "        \n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss_dogcat = F.cross_entropy(output_dogcat, target_dogcat, reduction=\"none\") \n",
    "        # we don't do reduction for dogcat branch right away, \n",
    "        # because we want to assign zero loss to samples\n",
    "        # which original class is neither dog nor cat in dogcat classification\n",
    "        loss_dogcat[(index_pred != 3) & (index_pred != 5)] = 0 \n",
    "        # now we can make reduction\n",
    "        loss_dogcat = torch.mean(loss_dogcat)\n",
    "        # calculate loss with two terms\n",
    "        loss = (1 - lambda_) * loss + lambda_ * loss_dogcat\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def test_dogcat(model: nn.Module) -> Tuple[float, List, List]:\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    \n",
    "    for data, target, target_dogcat in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output, output_dogcat = model(data)\n",
    "        \n",
    "        pred = output.data.max(\n",
    "            1, keepdim=True)[1]\n",
    "        pred_dogcat = output_dogcat.data.max(\n",
    "            1, keepdim=True)[1]\n",
    "        \n",
    "        for i, (p, p_dogcat) in enumerate(zip(pred, pred_dogcat)):\n",
    "            # if normal branch predicted dog or cat\n",
    "            # we look at the output of dogcat branch\n",
    "            # and assign final prediction for that sample\n",
    "            # based on the output of dogcat branch\n",
    "            if p.item() == 3 or p.item() == 5:\n",
    "                corrected_pred = convert_dogcat_to_normal(p_dogcat.item())\n",
    "                pred[i] = corrected_pred\n",
    "        \n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
    "\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Callable\n",
    "from datetime import datetime\n",
    "\n",
    "def train_and_test(epochs: int, model: nn.Module,\n",
    "                   create_optimizer: Callable, lr: float, lambda_: float):\n",
    "    date = datetime.now().strftime(\"%b%d_%H-%M-%S\")\n",
    "    START_seed()\n",
    "    optimizer = create_optimizer()\n",
    "    model.to(device)\n",
    "    test_accs = []\n",
    "    start = time.time()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        if epoch == 25:\n",
    "            lr = lr / 10\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "        \n",
    "        epoch_loss = train_dogcat(epoch, model, optimizer, lambda_)\n",
    "        epoch_test_accuracy = test_dogcat(model)\n",
    "        test_accs.append(epoch_test_accuracy)\n",
    "        print(f\"epoch={epoch} test_accuracy={epoch_test_accuracy}\")    \n",
    "    end = time.time()\n",
    "    Total_time=end-start\n",
    "    print('Total training and inference time is: {0}'.format(Total_time))\n",
    "    start = time.time()\n",
    "    accuracy = test_dogcat(model)\n",
    "    end = time.time()\n",
    "    Test_time=end-start\n",
    "    print('Total inference time is: {0}'.format(Test_time))\n",
    "    Training_time=Total_time-(Test_time*epochs)\n",
    "    print('Total Training time is: {0}'.format(Training_time))\n",
    "    max_test_acc = np.max(test_accs)\n",
    "    max_test_acc_epoch = np.argmax(test_accs)\n",
    "    print(f\"Array of test_accuracy by epoch {test_accs}.\")\n",
    "    print(f\"Maximum accuracy is {max_test_acc} and obtained on epoch {max_test_acc_epoch}.\")\n",
    "    print(\"Done\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 120277\n",
      "epoch=1 test_accuracy=43.02\n",
      "epoch=2 test_accuracy=64.01\n",
      "epoch=3 test_accuracy=66.71\n",
      "epoch=4 test_accuracy=71.86\n",
      "epoch=5 test_accuracy=67.64\n",
      "epoch=6 test_accuracy=74.2\n",
      "epoch=7 test_accuracy=78.96\n",
      "epoch=8 test_accuracy=76.3\n",
      "epoch=9 test_accuracy=76.12\n",
      "epoch=10 test_accuracy=73.43\n",
      "epoch=11 test_accuracy=77.67\n",
      "epoch=12 test_accuracy=79.07\n",
      "epoch=13 test_accuracy=81.83\n",
      "epoch=14 test_accuracy=79.73\n",
      "epoch=15 test_accuracy=79.0\n",
      "epoch=16 test_accuracy=80.23\n",
      "epoch=17 test_accuracy=77.17\n",
      "epoch=18 test_accuracy=77.87\n",
      "epoch=19 test_accuracy=81.82\n",
      "epoch=20 test_accuracy=74.77\n",
      "epoch=21 test_accuracy=79.96\n",
      "epoch=22 test_accuracy=77.52\n",
      "epoch=23 test_accuracy=80.92\n",
      "epoch=24 test_accuracy=82.21\n",
      "epoch=25 test_accuracy=88.17\n",
      "epoch=26 test_accuracy=88.42\n",
      "epoch=27 test_accuracy=88.48\n",
      "epoch=28 test_accuracy=88.43\n",
      "epoch=29 test_accuracy=88.74\n",
      "epoch=30 test_accuracy=88.36\n",
      "Total training and inference time is: 480.72797107696533\n",
      "Total inference time is: 2.0288233757019043\n",
      "Total Training time is: 419.8632698059082\n",
      "Array of test_accuracy by epoch [43.02, 64.01, 66.71, 71.86, 67.64, 74.2, 78.96, 76.3, 76.12, 73.43, 77.67, 79.07, 81.83, 79.73, 79.0, 80.23, 77.17, 77.87, 81.82, 74.77, 79.96, 77.52, 80.92, 82.21, 88.17, 88.42, 88.48, 88.43, 88.74, 88.36].\n",
      "Maximum accuracy is 88.74 and obtained on epoch 28.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "def create_optim() -> torch.optim:\n",
    "    return optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-3, nesterov=True)\n",
    "\n",
    "model = densenetdogcat_cifar()\n",
    "lr = 0.05\n",
    "lambda_ = 0.1\n",
    "print('Number of parameters: {0}'.format(sum(p.numel() for p in model.parameters())))\n",
    "train_and_test(epochs=30, model=model, lr=lr, lambda_=lambda_, create_optimizer=create_optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
